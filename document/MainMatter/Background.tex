\chapter{Preliminares}\label{chapter:state-of-the-art}

\section{Introducción al Análisis de Similitud de Código}
El análisis de similitud de código es un campo que ha evolucionado significativamente desde sus inicios en la década de 1970. Es utilizado en aplicaciones como la detección de plagio, refactorización de código, revisión de código y herramientas de asistencia a la programación. En esta sección se revisan los desarrollos históricos, metodologías y tecnologías clave, así como los avances recientes en este ámbito.

Los orígenes del análisis de similitud de código se remontan a los años 70 con los primeros algoritmos de coincidencia de cadenas, cuando se buscaban métodos para detectar plagio en tareas de programación. Algoritmos como Knuth-Morris-Pratt (KMP) \cite{knuth1977fast} y Boyer-Moore \cite{boyer1977fast} se utilizaron inicialmente para comparar secuencias de texto, sentando las bases para la comparación de código fuente.

En los 90, herramientas como MOSS (Measure of Software Similarity) \cite{aiken1994moss} fue un primer paso dentro de este ámbito. MOSS normaliza el código, eliminando comentarios y renombrando variables, para detectar similitudes estructurales y lógicas, incluso frente a modificaciones superficiales. Esta herramienta tuvo un impacto significativo en el ámbito académico, promoviendo la integridad académica.

\section{Técnicas Basadas en Árboles de Sintaxis Abstracta (AST)}

Originalmente desarrollados en los 80 para compiladores, los AST comenzaron a usarse en los 2000 para análisis y transformación de código \cite{aho1986compilers}. Permiten comparaciones basadas en la estructura lógica y sintáctica del código, superando las limitaciones de las comparaciones textuales simples.

Un Árbol de Sintaxis Abstracta (AST) es una representación jerárquica y estructurada de un código fuente. Cada nodo del árbol representa una construcción en el lenguaje de programación, como operadores, declaraciones o expresiones. Esta representación abstracta facilita el análisis de alto nivel del código, ignorando detalles superficiales como el formato o los comentarios.

I. Baxter et al. \cite{baxter1998clone} propusieron métodos que utilizan hashing para detectar clones exactos y casi coincidentes mediante subárboles de AST. Aunque efectivos, enfrentan desafíos como falsos positivos en la detección de clones complejos.

B. N. Pellin \cite{pellin2004authorship} utilizó SVM y AST para clasificar autoría en código fuente. Aunque precisa, esta técnica es vulnerable a manipulaciones avanzadas del código.

Comparar subárboles de AST permite detectar similitudes en diferentes niveles de granularidad. Esto incluye no solo similitudes textuales, sino también similitudes semánticas y estructurales que reflejan la lógica subyacente del código, incluso cuando este ha sido modificado para evitar detección directa.

\section{Avances en Análisis de Similitud de Código}

\subsection{Integración del Aprendizaje Automático}
Desde 2010, el aprendizaje automático ha mejorado la precisión del análisis de similitud de código. Técnicas como redes neuronales recurrentes (RNN) y convolucionales (CNN) generan representaciones vectoriales que capturan patrones estructurales complejos.

\subsection{Redes Neuronales Siamesas}
Las redes neuronales siamesas son un tipo de arquitectura de red diseñada para aprender similitudes entre pares de entradas. Originalmente propuestas por Bromley y LeCun \cite{bromley1993signature}, estas redes constan de dos ramas idénticas que comparten los mismos parámetros. Cada rama procesa una de las entradas y genera una representación vectorial de alto nivel.

La similitud entre las dos representaciones vectoriales se mide usando una métrica, como la distancia euclidiana o la similitud del coseno. Este enfoque permite identificar relaciones semánticas y estructurales entre fragmentos de código, incluso cuando no son idénticos textualmente.

Aplicaciones destacadas de redes siamesas incluyen la detección de plagio y la búsqueda de fragmentos de código similares en grandes bases de datos. Estas redes son especialmente útiles cuando se necesita comparar fragmentos de código que han sido modificados, ya que se centran en la esencia lógica y estructural de los fragmentos.

\subsection{Aplicaciones Modernas: Transformadores}
Transformadores como Codex de OpenAI y GitHub Copilot \cite{vaswani2017attention} han revolucionado el análisis de código. Su capacidad para manejar dependencias a largo plazo y procesar secuencias extensas permite tareas avanzadas como completar código y detectar similitudes.

\section{Representaciones Vectoriales y Aprendizaje Profundo}

Word2Vec se ha utilizado para generar representaciones vectoriales de fragmentos de código, capturando relaciones semánticas complejas. Sin embargo, su aplicación directa al código plantea desafíos debido a la estructura jerárquica inherente.

Desde 2014, se han empleado redes neuronales profundas (DNN) para aprender incrustaciones vectoriales de código. Estas técnicas han mejorado significativamente la precisión en la detección de similitudes y relaciones contextuales entre fragmentos de código.

Las representaciones vectoriales permiten realizar comparaciones más rápidas y precisas, ya que los fragmentos de código se transforman en puntos dentro de un espacio vectorial. Estas representaciones capturan tanto la estructura lógica como los patrones semánticos, lo que facilita la detección de similitudes en un nivel más abstracto.

\section{Conclusión}
El análisis de similitud de código ha evolucionado desde comparaciones textuales simples hasta técnicas avanzadas basadas en aprendizaje profundo y representaciones estructurales. Aunque las tecnologías actuales han mejorado significativamente la precisión y la eficiencia, persisten desafíos, como la escalabilidad y la manipulación intencional del código. Esto abre oportunidades para futuras investigaciones en métodos híbridos que combinen aprendizaje profundo y análisis estructural.
